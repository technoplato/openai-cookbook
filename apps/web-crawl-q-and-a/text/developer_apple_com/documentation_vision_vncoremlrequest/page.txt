https://developer.apple.com/documentation/vision/vncoremlrequest

Skip Navigation
Apple Developer
News
Discover
Design
Develop
Distribute
Support
Account
func VNImageRectForNormalizedRectUsingRegionOfInterest(CGRect, Int, Int, CGRect) -> CGRect
func VNNormalizedRectForImageRect(CGRect, Int, Int) -> CGRect
func VNImageRectForNormalizedRect(CGRect, Int, Int) -> CGRect
func VNNormalizedPointForImagePointUsingRegionOfInterest(CGPoint, Int, Int, CGRect) -> CGPoint
func VNImagePointForNormalizedPointUsingRegionOfInterest(CGPoint, Int, Int, CGRect) -> CGPoint
func VNNormalizedPointForImagePoint(CGPoint, Int, Int) -> CGPoint
func VNImagePointForNormalizedPoint(CGPoint, Int, Int) -> CGPoint
Training a Create ML Model to Classify Flowers
Classifying Images with Vision and Core ML
Machine Learning Image Analysis
Understanding a Dice Roll with Vision and Object Detection
C
VNRecognizedObjectObservation
Recognizing Objects in Live Capture
Object Recognition
V
let VNGenerateForegroundInstanceMaskRequestRevision1: Int
Beta
Documentation
Open Menu
Class
VNCoreMLRequest
An image analysis request that uses a Core ML model to process images.
iOS 11.0+
iPadOS 11.0+
macOS 10.13+
Mac Catalyst 13.1+
tvOS 11.0+
visionOS 1.0+ Beta
class VNCoreMLRequest : VNImageBasedRequest
Overview
The results array of a Core ML-based image analysis request contains a different observation type, depending on the kind of MLModel object you use:
If the model predicts a single feature, the model’s modelDescription object has a non-nil value for predictedFeatureName and Vision treats the model as a classifier. The results are VNClassificationObservation objects.
If the model’s outputs include at least one output with a feature type of MLFeatureType.image, Vision treats that model as an image-to-image model. The results are VNPixelBufferObservation objects.
Otherwise, Vision treats the model as a general predictor model. The results are VNCoreMLFeatureValueObservation objects.
Note
Vision forwards all confidence values from Core ML models as-is and doesn’t normalize them to [0, 1].
Topics
Initializing with a Core ML Model
init(model: VNCoreMLModel)
Creates a model container to use with an image analysis request based on the model you provide.
init(model: VNCoreMLModel, completionHandler: VNRequestCompletionHandler?)
Creates a model container to use with an image analysis request based on the model you provide, with an optional completion handler.
var model: VNCoreMLModel
The model to base the image analysis request on.
class VNCoreMLModel
A container for the model to use with Vision requests.
Configuring Image Options
var imageCropAndScaleOption: VNImageCropAndScaleOption
An optional setting that tells the Vision algorithm how to scale an input image.
enum VNImageCropAndScaleOption
Options that define how Vision crops and scales an input-image.
Identifying Request Revisions
let VNCoreMLRequestRevision1: Int
A constant for specifying revision 1 of a Core ML request.
Relationships
Inherits From
VNImageBasedRequest
See Also
Machine Learning Image Analysis
Classifying Images with Vision and Core ML
Crop and scale photos using the Vision framework and classify them with a Core ML model.
Training a Create ML Model to Classify Flowers
Train a flower classifier using Create ML in Swift Playgrounds, and apply the resulting model to real-time image classification using Vision.
class VNClassificationObservation
An object that represents classification information that an image analysis request produces.
class VNPixelBufferObservation
An object that represents an image that an image analysis request produces.
class VNCoreMLFeatureValueObservation
An object that represents a collection of key-value information that a Core ML image analysis request produces.
Beta Software
This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.
Learn more about using Apple's beta software
Current page is VNCoreMLRequest
Developer
Documentation
Platforms
iOS
iPadOS
macOS
tvOS
watchOS
visionOS
Tools
Swift
SwiftUI
Swift Playgrounds
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Business
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning
Security
Safari & Web
Resources
Documentation
Curriculum
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Events Overview
App Accelerators
App Store Awards
Apple Design Awards
Apple Developer Academies
Entrepreneur Camp
Ask Apple
Tech Talks
WWDC
To view the latest developer news, visit News and Updates .
Light
Dark
Auto
Copyright © 2023 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

