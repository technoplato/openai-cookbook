https://developer.apple.com/documentation/realitykit/body-and-face-trackingSkip Navigation
Apple Developer
News
Discover
Design
Develop
Distribute
Support
Account
Creating a game with scene understanding
Creating a Game with Reality Composer
SwiftStrike: Creating a Game with RealityKit
Happy Beam
Games
Runtime Events
Content synchronization
Transforms: Position, Orientation, and Scale
Runtime modifications
r
P
RealityCoordinateSpace
Beta
Animation
Audio
Scene reconstruction and understanding
Cameras and lighting
Anchors
Documentation
Open Menu
Swift
Body and face tracking
Track the movement and facial expressions of people in an AR scene
Overview
RealityKit can detect real-world people in an AR scene and track their movements and facial expressions. You can use this information to control the movement or expressions of character models or to superimpose entities and textures over the real world person.
Topics
Convenience Entity
class BodyTrackedEntity
An entity used to animate a virtual character in an AR scene by tracking a real person.
Face tracking
Creating an App for Face-Painting in AR
Combine RealityKit’s face detection with PencilKit to implement virtual face-painting.
Pose tracking
struct BodyTrackingComponent
A component for tracking people in an AR session.
struct JointTransforms
A set of animatable transform values for joints that collectively represent a single skeletal pose.
People Occlusion
Occluding Virtual Content with People
Cover your app’s virtual content with people that ARKit perceives in the camera feed.
Entity compliance
protocol HasBodyTracking
An interface that enables the animation of a virtual character by tracking a real person in AR.
See Also
Runtime modifications
API Reference
Transforms: Position, Orientation, and Scale
Control the placement of virtual objects.
API Reference
Collision detection
Determine when entities collide with each other or the environment.
API Reference
Physics simulation
Simulate physical interactions between entities.
API Reference
Postprocessing effects
Create special rendering effects for your RealityKit scenes.
API Reference
Content synchronization
Synchronize the contents of entities locally or across the network.
API Reference
Runtime Events
Execute code when specific things happen in your RealityKit scene.
Current page is Body and face tracking
Developer
Documentation
Platforms
iOS
iPadOS
macOS
tvOS
watchOS
visionOS
Tools
Swift
SwiftUI
Swift Playgrounds
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Business
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning
Security
Safari & Web
Resources
Documentation
Curriculum
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Events Overview
App Accelerators
App Store Awards
Apple Design Awards
Apple Developer Academies
Entrepreneur Camp
Ask Apple
Tech Talks
WWDC
To view the latest developer news, visit News and Updates .
Light
Dark
Auto
Copyright © 2023 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

