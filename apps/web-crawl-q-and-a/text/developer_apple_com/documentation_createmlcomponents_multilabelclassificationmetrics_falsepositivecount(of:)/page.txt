https://developer.apple.com/documentation/createmlcomponents/multilabelclassificationmetrics/falsepositivecount(of:)

Skip Navigation
Apple Developer
News
Discover
Design
Develop
Distribute
Support
Account
P
var labels: Set<Label>
P
var meanAveragePrecision: Float
Instance Methods
M
func add(some Sequence<(classification: ClassificationDistribution<Label>, labels: Set<Label>)>)
M
func add(classifications: some Sequence<ClassificationDistribution<Label>>, groundTruth: some Sequence<Set<Label>>)
M
func count(of: Label) -> Int
M
func f1Score(for: Label) -> Float
M
func falseNegativeCount(of: Label) -> Int
static func meanAveragePrecisionScore(some Sequence<(classification: ClassificationDistribution<Label>, labels: Set<Label>)>) -> Float
static func meanAveragePrecisionScore(some Sequence<(classification: ClassificationDistribution<Label>, labels: Set<Label>)>, labels: Set<Label>) -> Float
static func meanAveragePrecisionScore(classifications: some Sequence<ClassificationDistribution<Label>>, groundTruth: some Sequence<Set<Label>>) -> Float
static func meanAveragePrecisionScore(classifications: some Sequence<ClassificationDistribution<Label>>, groundTruth: some Sequence<Set<Label>>, labels: Set<Label>) -> Float
S
UpsampledAugmentationSequence
Functions
func maximumAbsoluteError<T>([AnnotatedPrediction<T, T>]) -> T
Beta
func meanAbsoluteError<T>([AnnotatedPrediction<T, T>]) -> T
Beta
func meanAbsolutePercentageError<T>([AnnotatedPrediction<T, T>]) -> T
Beta
func rootMeanSquaredError<T>([AnnotatedPrediction<T, T>]) -> T
Beta
Enumerations
Documentation
Open Menu
Swift
Instance Method
falsePositiveCount(of:)
Returns the number of times the predicted label did not match the true label.
Create ML Components
CreateMLComponents
iOS 17.0+ Beta
iPadOS 17.0+ Beta
macOS 14.0+ Beta
Mac Catalyst 17.0+ Beta
tvOS 17.0+ Beta
visionOS 1.0+ Beta
func falsePositiveCount(of label: Label) -> Int
Available when Label conforms to Hashable.
Parameters
label
The label to use as true positive.
Return Value
The false positive count.
Discussion
If the label does not have a confidence threshold, the false positive count is the number of elements in the ground truth labels collection that do not contain the label. If the label has a confidence threshold NaN, the false positive count is 0. If the label is not in the known set of labels, the false positive count is 0.
Beta Software
This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.
Learn more about using Apple's beta software
Current page is falsePositiveCount(of:)
Developer
Documentation
Platforms
iOS
iPadOS
macOS
tvOS
watchOS
visionOS
Tools
Swift
SwiftUI
Swift Playgrounds
TestFlight
Xcode
Xcode Cloud
SF Symbols
Topics & Technologies
Accessibility
Accessories
App Extension
App Store
Audio & Video
Augmented Reality
Business
Design
Distribution
Education
Fonts
Games
Health & Fitness
In-App Purchase
Localization
Maps & Location
Machine Learning
Security
Safari & Web
Resources
Documentation
Curriculum
Downloads
Forums
Videos
Support
Support Articles
Contact Us
Bug Reporting
System Status
Account
Apple Developer
App Store Connect
Certificates, IDs, & Profiles
Feedback Assistant
Programs
Apple Developer Program
Apple Developer Enterprise Program
App Store Small Business Program
MFi Program
News Partner Program
Video Partner Program
Security Bounty Program
Security Research Device Program
Events
Events Overview
App Accelerators
App Store Awards
Apple Design Awards
Apple Developer Academies
Entrepreneur Camp
Ask Apple
Tech Talks
WWDC
To view the latest developer news, visit News and Updates .
Light
Dark
Auto
Copyright Â© 2023 Apple Inc. All rights reserved. Terms of Use Privacy Policy Agreements and Guidelines

